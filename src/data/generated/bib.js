const generatedBibEntries = {
    "8848063": {
        "author": "Justesen, Niels and Uth, Lasse M\u00f8ller and Jakobsen, Christopher and Moore, Peter David and Togelius, Julian and Risi, Sebastian",
        "booktitle": "2019 IEEE Conference on Games (CoG)",
        "doi": "10.1109/CIG.2019.8848063",
        "keywords": "Games;Blood;Sports;Reinforcement learning;Injuries;Conferences",
        "number": "",
        "pages": "1-8",
        "title": "Blood Bowl: A New Board Game Challenge and Competition for AI",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2019"
    },
    "Perolat_2022": {
        "author": "Perolat, Julien and De Vylder, Bart and Hennes, Daniel and Tarassov, Eugene and Strub, Florian and de Boer, Vincent and Muller, Paul and Connor, Jerome T. and Burch, Neil and Anthony, Thomas and McAleer, Stephen and Elie, Romuald and Cen, Sarah H. and Wang, Zhe and Gruslys, Audrunas and Malysheva, Aleksandra and Khan, Mina and Ozair, Sherjil and Timbers, Finbarr and Pohlen, Toby and Eccles, Tom and Rowland, Mark and Lanctot, Marc and Lespiau, Jean-Baptiste and Piot, Bilal and Omidshafiei, Shayegan and Lockhart, Edward and Sifre, Laurent and Beauguerlange, Nathalie and Munos, Remi and Silver, David and Singh, Satinder and Hassabis, Demis and Tuyls, Karl",
        "doi": "10.1126/science.add4679",
        "issn": "1095-9203",
        "journal": "Science",
        "keywords": "Stratego, Multiagent Reinforcement Learning, Game AI, Model-Free Learning",
        "month": "dec,",
        "number": "6623",
        "pages": "990--996",
        "publisher": "American Association for the Advancement of Science (AAAS)",
        "title": "Mastering the game of Stratego with model-free multiagent reinforcement learning",
        "type": "article",
        "url": "http://dx.doi.org/10.1126/science.add4679",
        "volume": "378",
        "year": "2022"
    },
    "YANG2024100707": {
        "abstract": "Especially with the rise of artificial intelligence, people need more ability to think logically and make judgments than before. Board games can be used as a tool for training logic, which has a positive effect on the sustainable development of society. Connect6 is a very popular board game because it is a fair and highly complex game with simple rules. This research aims to address the technical challenges of building a game-based logical learning system with a deep neural network for Connect6. We used heuristic knowledge to establish the knowledge base. Our novel algorithm, based on residual deep convolutional neural networks (DCNNs), outperforms conventional approaches. We compare neural network architectures, demonstrating the superiority of residual DCNNs.Our AI program, \u201cKavalan,\u201d achieves remarkable search performance. Furthermore, the introduced approaches lend themselves to application in other sudden-death board games, such as Gomoku, the endgame of Chess and Shogi.",
        "author": "Jung-Kuei Yang and Shi-Jim Yen and Serkan Kavak",
        "doi": "https://doi.org/10.1016/j.entcom.2024.100707",
        "issn": "1875-9521",
        "journal": "Entertainment Computing",
        "keywords": "Board Games, Connect6, Deep Neural Networks, Residual DCNN, Knowledge Base",
        "pages": "100707",
        "title": "Deep learning approaches to the game of Connect6",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S1875952124000752",
        "volume": "50",
        "year": "2024"
    },
    "app11052056": {
        "abstract": "Monte Carlo Tree Search is one of the main search methods studied presently. It has demonstrated its efficiency in the resolution of many games such as Go or Settlers of Catan and other different problems. There are several optimizations of Monte Carlo, but most of them need heuristics or some domain language at some point, making very difficult its application to other problems. We propose a general and optimized implementation of Monte Carlo Tree Search using neural networks without extra knowledge of the problem. As an example of our proposal, we made use of the Dots and Boxes game. We tested it against other Monte Carlo system which implements specific knowledge for this problem. Our approach improves accuracy, reaching a winning rate of 81% over previous research but the generalization penalizes performance.",
        "article-number": "2056",
        "author": "Cotarelo, Alba and Garc\u00eda-D\u00edaz, Vicente and N\u00fa\u00f1ez-Valdez, Edward Rolando and Gonz\u00e1lez Garc\u00eda, Cristian and G\u00f3mez, Alberto and Chun-Wei Lin, Jerry",
        "doi": "10.3390/app11052056",
        "issn": "2076-3417",
        "journal": "Applied Sciences",
        "keywords": "Monte Carlo Tree Search, Artificial Neural Networks, Heuristic-Free, Game Optimization, Dots and Boxes",
        "number": "5",
        "title": "Improving Monte Carlo Tree Search with Artificial Neural Networks without Heuristics",
        "type": "Article",
        "url": "https://www.mdpi.com/2076-3417/11/5/2056",
        "volume": "11",
        "year": "2021"
    },
    "electronics10212609": {
        "abstract": "Artificial intelligence allows computer systems to make decisions similar to those of humans. However, the expert knowledge that artificial intelligence systems have is rarely used to teach non-expert humans in a specific knowledge domain. In this paper, we want to explore this possibility by proposing a tool which presents and explains recommendations for playing board games generated by a Monte Carlo Tree Search algorithm combined with Neural Networks. The aim of the aforementioned tool is to showcase the information in an easily interpretable way and to effectively transfer knowledge: in this case, which movements should be avoided, and which action is recommended. Our system displays the state of the game in the form of a tree, showing all the movements available from the current state and a set of their successors. To convince and try to teach people, the tool offers a series of queries and all information available about every possible movement. In addition, it produces a brief textual explanation for those which are recommended or not advisable. To evaluate the tool, we performed a series of user tests, observing and assessing how participants learn while using this system.",
        "article-number": "2609",
        "author": "Gonzalo-Crist\u00f3bal, V\u00edctor and N\u00fa\u00f1ez-Valdez, Edward Rolando and Garc\u00eda-D\u00edaz, Vicente and Gonz\u00e1lez Garc\u00eda, Cristian and Cotarelo, Alba and G\u00f3mez, Alberto",
        "doi": "10.3390/electronics10212609",
        "issn": "2079-9292",
        "journal": "Electronics",
        "keywords": "Monte Carlo Tree Search, Self-Learning, Board Games, Neural Networks, Teaching Tool",
        "number": "21",
        "title": "Monte Carlo Tree Search as a Tool for Self-Learning and Teaching People to Play Complete Information Board Games",
        "type": "Article",
        "url": "https://www.mdpi.com/2079-9292/10/21/2609",
        "volume": "10",
        "year": "2021"
    },
    "jiang_2023": {
        "author": "Jiang, Chengyi",
        "doi": "10.54254/2755-2721/4/20230497",
        "journal": "Applied and Computational Engineering",
        "keywords": "Artificial Intelligence, Board Games, AI Applications, Game Strategies",
        "month": "Jun",
        "number": "1",
        "pages": "383--386",
        "title": "The application of artificial intelligence in board games",
        "type": "article",
        "volume": "4",
        "year": "2023"
    },
    "karmanova2021swarmplay": {
        "archiveprefix": "arXiv",
        "author": "Ekaterina Karmanova and Valerii Serpiva and Stepan Perminov and Aleksey Fedoseev and Dzmitry Tsetserukou",
        "doi": "10.48550/arxiv.2108.01593",
        "eprint": "2108.01593",
        "keywords": "SwarmPlay, Tic-tac-toe, Nano-UAVs, Reinforcement Learning, Interactive Games",
        "primaryclass": "cs.HC",
        "title": "SwarmPlay: Interactive Tic-tac-toe Board Game with Swarm of Nano-UAVs driven by Reinforcement Learning",
        "type": "misc",
        "year": "2021"
    },
    "l\u00fcrig_2022": {
        "author": "L\u00fcrig, Christoph",
        "doi": "10.34190/ecgbl.16.1.481",
        "journal": "European Conference on Games Based Learning",
        "keywords": "strategy gamers, reinforcement learning, explainable AI",
        "month": "Sep",
        "number": "1",
        "pages": "316--323",
        "title": "Learning Machine Learning with a Game",
        "type": "article",
        "volume": "16",
        "year": "2022"
    },
    "saito_miwa_2021": {
        "author": "Saito, Masato and Miwa, Hiroyoshi",
        "doi": "10.1007/978-3-030-84910-8_7",
        "journal": "Lecture Notes in Networks and Systems",
        "keywords": "Nanahoshi, Deep Neural Networks, Board Games, AI Algorithms, Game Mastery",
        "month": "Aug",
        "pages": "59--69",
        "publisher": "Springer International Publishing",
        "title": "Algorithms for Mastering Board Game Nanahoshi Considering Deep Neural Networks",
        "type": "article",
        "year": "2021"
    },
    "zhang2024development": {
        "archiveprefix": "arXiv",
        "author": "Ye Zhang and Mengran Zhu and Kailin Gui and Jiayue Yu and Yong Hao and Haozhan Sun",
        "doi": "10.48550/arxiv.2403.10720",
        "eprint": "2403.10720",
        "keywords": "Monte Carlo Tree Search, Da Vinci Code Game, Game Strategies, Simulation, AI",
        "primaryclass": "cs.AI",
        "title": "Development and Application of a Monte Carlo Tree Search Algorithm for Simulating Da Vinci Code Game Strategies",
        "type": "misc",
        "year": "2024"
    }
};